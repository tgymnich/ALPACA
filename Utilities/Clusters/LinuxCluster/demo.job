#!/bin/sh

# Initial working directory:
#SBATCH -D <InitialDir>

# Job name
#SBATCH -J <JobName>

# Output and error files
#SBATCH -o %j-%x.out
#SBATCH -e %j-%x.err

# Notification
#SBATCH --mail-type=end
#SBATCH --mail-user=<your-email>@<your-host.domain>

# Where to run the simulation
#SBATCH --clusters=<cluster>
#SBATCH --partition=<partition>
#SBATCH --qos=<QOS>

# Request ressources
#SBATCH --nodes=<#Nodes>
#SBATCH --tasks-per-node=28
#SBATCH --time=<HH:MM:SS>

# Setup execution environment
#SBATCH --export=NONE
#SBATCH --get-user-env
module load slurm_setup
module load hdf5/1.8.21-intel19-impi

## Commenting in the following line may help with stalling I/O
## export I_MPI_EXTRA_FILESYSTEM=on

## In case of RAM shortage try using mpiexec's -rr option (not supported by all MPI Libraries)
mpiexec -n $SLURM_NTASKS ./ALPACA ./<your-inputfile>.xml
